{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, pipeline, AutoProcessor\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'openai/whisper-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, \n",
    "                                                  torch_dtype=torch_dtype, \n",
    "                                                  low_cpu_mem_usage = True,\n",
    "                                                  use_safetensors = True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 384)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 384, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 384)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=384, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                model=model,\n",
    "                tokenizer=processor.tokenizer,\n",
    "                feature_extractor=processor.feature_extractor,\n",
    "                max_new_tokens = 128,\n",
    "                chunk_length_s = 30,\n",
    "                batch_size = 16,\n",
    "                return_timestamps = True,\n",
    "                torch_dtype=torch_dtype,\n",
    "                device=device \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Wake up to reality. Nothing ever goes as planned in this accursed world. The longer you live the more you'll realize that the only things that truly exist in this reality are merely pain, suffering and futility. Listen, everywhere you look in this world, wherever there is light, there will always be shadows to be found as well. As long as there is a concept of victors, the fact pushed will also exist. The selfish intent of wanting to preserve peace, initiate wars, and hatred is borne at order to protect love. There are nexus, causal relationships that cannot be separated. I want to sever the fate of this world. A world of only victors, a world of only peace, a world of only love. I will create such a world. I will create such a world. I am the ghost of the U.G.R. For truly this reality, is our hell.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[0]['audio']\n",
    "result = pipe(\"Madara.mp3\")\n",
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.8088902235031128},\n",
       " {'label': 'positive', 'score': 0.12696124613285065},\n",
       " {'label': 'neutral', 'score': 0.06414858251810074}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = distilled_student_sentiment_classifier(result['text'])\n",
    "sent = sent[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'negative', 'score': 0.8088902235031128}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sent[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Wake up to reality. Nothing ever goes as planned in this accursed world. The longer you live the more you'll realize that the only things that truly exist in this reality are merely pain, suffering and futility. Listen, everywhere you look in this world, wherever there is light, there will always be shadows to be found as well. As long as there is a concept of victors, the fact pushed will also exist. The selfish intent of wanting to preserve peace, initiate wars, and hatred is borne at order to protect love. There are nexus, causal relationships that cannot be separated. I want to sever the fate of this world. A world of only victors, a world of only peace, a world of only love. I will create such a world. I will create such a world. I am the ghost of the U.G.R. For truly this reality, is our hell.\n",
      " The Given text has a negative Marking with a overall score of 80.89%\n"
     ]
    }
   ],
   "source": [
    "ratings = []\n",
    "label = []\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    ratings.append(sent[i]['score'])\n",
    "    label.append(sent[i]['label'])\n",
    "\n",
    "maxi = max(ratings)\n",
    "rightLabel = ratings.index(maxi)\n",
    "\n",
    "\n",
    "print(f\"{result['text']}\\n The Given text has a {label[rightLabel]} Marking with a overall score of {maxi*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
